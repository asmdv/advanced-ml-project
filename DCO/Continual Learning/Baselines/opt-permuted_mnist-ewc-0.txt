----------------- Options ---------------
                ae_cl_lam: 100                           
                ae_epochs: 200                           
             ae_grad_norm: 20                            
              ae_lr_gamma: 1.0                           
                  ae_mean: False                         
            ae_offline_lr: 0.01                          
            ae_offline_ps: 0.0                           
             ae_online_lr: 0.01                          
             ae_online_ps: 0.0                           
                  ae_para: True                          
                ae_re_lam: 100                           
          ae_saved_epochs: 100                           
                  ae_topk: 1000                          
          ae_weight_decay: 0.0                           
                  ae_what: M                             
               cl_dataset: permuted_mnist                
                cl_epochs: 10                            
                cl_method: ewc                           
          cone_batch_size: 128                           
                   device: cpu                           
      episodic_batch_size: 256                           
        episodic_mem_size: 256                           
                  ewc_lam: 10.0                          
         fisher_ema_decay: 0.9                           
      fisher_update_after: 100                           
                in_epochs: 1                             
                  is_grad: False                         
            is_mlps_saved: False                         
                   is_svd: False                         
        l2_regularization: 0.0                           
                lr_epochs: 10                            
            main_lr_gamma: 1.0                           
           main_online_lr: 0.001                         
           main_optimizer: sgd                           
                main_para: True                          
         mlp_saved_epochs: 10                            
     mlp_saved_iterations: 512                           
                num_tasks: 5                             
          post_batch_size: 128                           
              prox_epochs: 10                            
             push_cone_l2: 0.0                           
                     rank: 0                             
            rwalk_epsilon: 0.1                           
                rwalk_lam: 1                             
         sample_posterior: False                         
                     seed: 1                             
               si_epsilon: 0.1                           
                   si_lam: 100                           
          test_batch_size: 1024                          
         train_batch_size: 128                           
                       wd: 0.001                         
----------------- End -------------------
